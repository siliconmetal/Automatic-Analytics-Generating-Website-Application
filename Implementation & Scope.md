Since I developed the application for a software-developing company, I am not supposed to share the code, so I would briefly explain the implementation with a few snippets and the scope of this application.

### 1. Implementaion

#### 1.1 First Step 
For the first go-trying multiple libraries and logics-started developing the application on Jupyter Notebook, I find Jupyter Notebook quite handy as it allows to check the implementation of each sub-script or logic individually and in a sequential manner, and tried multiple libraries and logic out of which Stremlit suited the most.

![Screenshot (1087)](https://user-images.githubusercontent.com/42034100/224525715-3be73a79-d17c-498e-a99c-56c775146674.png)


#### 1.2 Starting Web Application Development 
Started the back-end development of the application in Pycharm using the required libraries. Developing is quite a long process where each feature of the application is individually coded and adjoined with the overall logic overcoming soo many errors, leading to the final implementation.

![specificmodels](https://user-images.githubusercontent.com/42034100/224525920-11db6a2a-f55a-4747-bab9-fedb7cf0e0ca.png)
![productionfile](https://user-images.githubusercontent.com/42034100/224525925-5edc0634-db4f-497a-86d7-6c422a0ddfda.png)


#### 1.3 The UI
Using Streamlit the user interface was designed. Firstly, the user needed to upload the data file under a total of five categories, as per their requirements, and then depending upon the data uploaded after backend analysis data will be visualized using tabular and chart representations as per entity correlation.

![Fbprophat-chart](https://user-images.githubusercontent.com/42034100/224528006-8dc816ff-bb59-471f-bc86-e12889c2dd82.jpeg)
![Neuralprophet-chart](https://user-images.githubusercontent.com/42034100/224528008-dbd16d59-76fa-493f-9764-7244698a4d44.jpeg)
![Arima-chart](https://user-images.githubusercontent.com/42034100/224528009-03a18207-33cb-4956-b9d8-73c6f405d2fb.jpeg)


#### 1.4 Testing
After the application meet all the requirements, it was hosted on Heroku, making it accessible for testing. Alpha & beta testing were performed with fellow developers working on different projects and a few active customers/future users.


### 2. Scope of the application
The application was built to provide easy-to-get and easy-to-interpret information to textile industry stakeholders. In technical terms, the application is built using Python programming and initially hosting the back-end logic and UI on a cloud platform for primary testing and later including the feature. It supports data files in multiple formats providing easy to use interface without any technical requirements, in fact, just drag-and-drop using a single click.
